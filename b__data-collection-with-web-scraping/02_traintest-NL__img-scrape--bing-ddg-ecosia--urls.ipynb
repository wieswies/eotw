{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0c00e1-e081-44f5-a9d6-18c806028298",
   "metadata": {},
   "source": [
    "#### Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2697209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wiesruyters/miniconda3/envs/multimodalmedia/lib/python3.12/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "# For necessary data processing and calculations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For reading and writing files\n",
    "import json\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import io\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "\n",
    "# For image processing\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import face_recognition\n",
    "import dlib\n",
    "import cv2\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# For face-embedding calculation\n",
    "from keras_facenet import FaceNet as FN\n",
    "\n",
    "# For machine learning\n",
    "import tensorflow as tf\n",
    "\n",
    "# For web scraping\n",
    "import html\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# For tracking programming progress\n",
    "from tqdm.notebook import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98d05ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b335075-d57a-4dd8-839c-8c64b9040e5e",
   "metadata": {},
   "source": [
    "# NL data collection for train/test image scraping\n",
    "This notebook contains the scraping method that obtains image references from three different search engines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617ee6da-662b-4138-a5ba-5f718d983fb7",
   "metadata": {},
   "source": [
    "##### Set-up web driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "541f17f9-f966-42dc-816b-3a7cc8f9ec46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wd = webdriver.Firefox()\n",
    "wd.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22803d89-9baa-42e9-8460-2695bc3b1211",
   "metadata": {},
   "source": [
    "### Define methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5af2cbe1-cb5e-40d4-a379-9627abdbbe2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_links_ddg(search_query, num_results, headless=True):\n",
    "    \"\"\"\n",
    "    DuckDuckGo image scraper\n",
    "    \"\"\"\n",
    "    ddg_search_url = f'https://duckduckgo.com/?q={search_query}&iax=images&ia=images'\n",
    "    \n",
    "    options = webdriver.SafariOptions()\n",
    "    if headless:\n",
    "        options.add_argument('--headless')\n",
    "    \n",
    "    driver = webdriver.Safari(options=options)\n",
    "    \n",
    "    try:\n",
    "        print(f\"Fetching DuckDuckGo results for: {search_query}\")\n",
    "        driver.get(ddg_search_url)\n",
    "        time.sleep(2) \n",
    "        \n",
    "        # Scroll\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        scroll_attempts = 0\n",
    "        \n",
    "        while scroll_attempts < 5:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # Check if bottom is reached or enough image urls are obtained\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "            \n",
    "            # Check for images\n",
    "            image_elements = driver.find_elements(By.CSS_SELECTOR, 'img[data-src], img[src*=\"external-content.duckduckgo.com\"]')\n",
    "            if len(image_elements) >= num_results:\n",
    "                break\n",
    "            scroll_attempts += 1\n",
    "        \n",
    "        # Find all image elements\n",
    "        image_elements = driver.find_elements(By.CSS_SELECTOR, 'img[data-src], img[src*=\"external-content.duckduckgo.com\"]')\n",
    "        \n",
    "        # Extract both src and data-src attr\n",
    "        links = []\n",
    "        for img in image_elements[:num_results]:\n",
    "            src = img.get_attribute('src') or img.get_attribute('data-src')\n",
    "            if src:\n",
    "                if src.startswith('//'):\n",
    "                    src = 'https:' + src\n",
    "                links.append(src)\n",
    "        \n",
    "        politician_array = [search_query] * len(links)\n",
    "        \n",
    "        print(f\"Found {len(links)} images for {search_query}\")\n",
    "        return politician_array, links\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while scraping DuckDuckGo for {search_query}: {str(e)}\")\n",
    "        return [search_query], []\n",
    "\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462a3e37-68a8-4cc6-b698-1e474b7e6417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_links_bing(search_query, num_results, max_retries=3, headless=True):\n",
    "    \"\"\"\n",
    "    Bing image scraper \n",
    "    \"\"\"\n",
    "    bing_search_url = f'https://www.bing.com/images/search?q={search_query.replace(\" \", \"+\")}'\n",
    "\n",
    "    options = webdriver.SafariOptions()\n",
    "    if headless:\n",
    "        options.add_argument('--headless')\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        driver = None\n",
    "        try:\n",
    "            driver = webdriver.Safari(options=options)\n",
    "            driver.get(bing_search_url)\n",
    "            print(f\"Attempt {attempt + 1}/{max_retries}: Fetching Bing results for '{search_query}'\")\n",
    "            \n",
    "            time.sleep(2)\n",
    "            \n",
    "            # Scroll\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            images_collected = 0\n",
    "            scroll_attempts = 0\n",
    "            \n",
    "            while scroll_attempts < 5 and images_collected < num_results:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(2)\n",
    "                \n",
    "                # Check if bottom is reached or enough image urls are obtained\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "                \n",
    "                # Find all image elements\n",
    "                image_elements = driver.find_elements(\n",
    "                    By.CSS_SELECTOR, \n",
    "                    'img.mimg:not([src^=\"data:\"])'\n",
    "                )\n",
    "                images_collected = len(image_elements)\n",
    "                scroll_attempts += 1\n",
    "            \n",
    "            # Extract image URLs\n",
    "            image_elements = driver.find_elements(\n",
    "                By.CSS_SELECTOR, \n",
    "                'img.mimg[src]:not([src^=\"data:\"])'\n",
    "            )\n",
    "            \n",
    "            links = []\n",
    "            for img in image_elements[:num_results]:\n",
    "                src = img.get_attribute('src')\n",
    "                if src and not src.startswith('data:'):\n",
    "                    # Cover for relative URLs\n",
    "                    if src.startswith('/'):\n",
    "                        src = f'https://www.bing.com{src}'\n",
    "                    links.append(src)\n",
    "            \n",
    "            if not links:\n",
    "                print(f\"No image links found for '{search_query}' (attempt {attempt + 1})\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(5 * (attempt + 1))\n",
    "                    continue\n",
    "                return [search_query], []\n",
    "            \n",
    "            politician_array = [search_query] * len(links)\n",
    "            print(f\"Successfully collected {len(links)} images for '{search_query}'\")\n",
    "            return politician_array, links\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed for '{search_query}': {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = 5 * (attempt + 1)\n",
    "                print(f\"Waiting {wait_time} seconds before retry...\")\n",
    "                time.sleep(wait_time)\n",
    "            \n",
    "        finally:\n",
    "            if driver:\n",
    "                driver.quit()\n",
    "    \n",
    "    return [search_query], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6788689b-7f83-4e35-bd93-10c8588fab12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_links_ecosia(search_query, num_results, max_retries=3, headless=True):\n",
    "    \"\"\"\n",
    "    Ecosia image scraper\n",
    "    \"\"\"\n",
    "    ecosia_search_url = f'https://www.ecosia.org/images?q={search_query.replace(\" \", \"+\")}'\n",
    "    \n",
    "    options = webdriver.SafariOptions()\n",
    "    if headless:\n",
    "        options.add_argument('--headless')\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        driver = None\n",
    "        try:\n",
    "            driver = webdriver.Safari(options=options)\n",
    "            print(f\"Attempt {attempt + 1}/{max_retries}: Fetching Ecosia results for '{search_query}'\")\n",
    "            \n",
    "            driver.set_page_load_timeout(30)\n",
    "            driver.get(ecosia_search_url)\n",
    "            \n",
    "            # Wait\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \".image-result__link-wrapper\"))\n",
    "            )\n",
    "            \n",
    "            # Scroll\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            images_collected = 0\n",
    "            scroll_attempts = 0\n",
    "            \n",
    "            while scroll_attempts < 5 and images_collected < num_results:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(2)\n",
    "                \n",
    "                # Check if bottom is reached\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "                \n",
    "                # Count the number of images collected\n",
    "                image_elements = driver.find_elements(By.CSS_SELECTOR, '.image-result__link-wrapper')\n",
    "                images_collected = len(image_elements)\n",
    "                scroll_attempts += 1\n",
    "            \n",
    "            # Extract both href and src attributes\n",
    "            image_wrappers = driver.find_elements(\n",
    "                By.CSS_SELECTOR, \n",
    "                '.image-result__link-wrapper'\n",
    "            )\n",
    "            \n",
    "            links = []\n",
    "            for wrapper in image_wrappers[:num_results]:\n",
    "                try:\n",
    "                    # First: href\n",
    "                    link = wrapper.find_element(By.CSS_SELECTOR, 'a.image-result__link')\n",
    "                    href = link.get_attribute('href')\n",
    "                    \n",
    "                    # Fallback: src\n",
    "                    if not href:\n",
    "                        img = wrapper.find_element(By.CSS_SELECTOR, 'img.image-result__image')\n",
    "                        href = img.get_attribute('src')\n",
    "                    \n",
    "                    if href:\n",
    "                        links.append(href)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Couldn't extract link from one result: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            if not links:\n",
    "                print(f\"No image links found for '{search_query}' (attempt {attempt + 1})\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(5 * (attempt + 1))\n",
    "                    continue\n",
    "                return [search_query], []\n",
    "            \n",
    "            politician_array = [search_query] * len(links)\n",
    "            print(f\"Successfully collected {len(links)} images for '{search_query}'\")\n",
    "            return politician_array, links\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed for '{search_query}': {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = 5 * (attempt + 1)\n",
    "                print(f\"Waiting {wait_time} seconds before retry...\")\n",
    "                time.sleep(wait_time)\n",
    "            \n",
    "        finally:\n",
    "            if driver:\n",
    "                driver.quit()\n",
    "    \n",
    "    return [search_query], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7de667-aac5-4744-a1e7-3facb9807a3a",
   "metadata": {},
   "source": [
    "### Create database with image links\n",
    "Create a list of politician names and set a limit on the number of image links to be extracted. <br>\n",
    "For the NL, this list is based on: https://nl.wikipedia.org/wiki/Tweede_Kamerverkiezingen_2023 & https://app.nos.nl/nieuws/tk2023/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a4df4be-c8af-49b2-ab72-00ee341d27ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nl_politicians_23 = [\n",
    "    'Geert Wilders',            # PVV\n",
    "    'Frans Timmermans',         # GL-PvdA\n",
    "    'Dilan Yesilgöz',           # VVD\n",
    "    'Pieter Omtzigt',           # NSC\n",
    "    'Rob Jetten',               # D66\n",
    "    'Caroline van der Plas',    # BBB\n",
    "    'Henri Bontenbal',          # CDA\n",
    "    'Lilian Marijnissen',       # SP\n",
    "    'Thierry Baudet',           # FVD\n",
    "    'Esther Ouwehand',          # PvdD\n",
    "    'Mirjam Bikker',            # CU\n",
    "    'Chris Stoffer',            # SGP\n",
    "    'Stephan van Baarle',       # DENK\n",
    "    'Laurens Dassen',           # Volt\n",
    "    'Joost Eerdmans',           # JA21\n",
    "    'Edson Olf',                # Bij1\n",
    "    'Wybren van Haga']          # BvNL\n",
    "\n",
    "num_results = 125\n",
    "image_link_list = []\n",
    "politician_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95bcccf-e72b-49b3-8d7d-273469651dba",
   "metadata": {},
   "source": [
    "#### DuckDuckGo image links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4563b17c-232b-4e41-b091-f72536a41861",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching DuckDuckGo results for: Geert Wilders\n",
      "Found 125 images for Geert Wilders\n",
      "Completed the extraction of 125 for politician Geert Wilders in 0 minutes and 6.04 seconds\n",
      "Fetching DuckDuckGo results for: Frans Timmermans\n",
      "Found 125 images for Frans Timmermans\n",
      "Completed the extraction of 125 for politician Frans Timmermans in 0 minutes and 5.74 seconds\n",
      "Fetching DuckDuckGo results for: Dilan Yesilgöz\n",
      "Found 125 images for Dilan Yesilgöz\n",
      "Completed the extraction of 125 for politician Dilan Yesilgöz in 0 minutes and 5.84 seconds\n",
      "Fetching DuckDuckGo results for: Pieter Omtzigt\n",
      "Found 125 images for Pieter Omtzigt\n",
      "Completed the extraction of 125 for politician Pieter Omtzigt in 0 minutes and 5.68 seconds\n",
      "Fetching DuckDuckGo results for: Rob Jetten\n",
      "Found 125 images for Rob Jetten\n",
      "Completed the extraction of 125 for politician Rob Jetten in 0 minutes and 5.81 seconds\n",
      "Fetching DuckDuckGo results for: Caroline van der Plas\n",
      "Found 125 images for Caroline van der Plas\n",
      "Completed the extraction of 125 for politician Caroline van der Plas in 0 minutes and 5.71 seconds\n",
      "Fetching DuckDuckGo results for: Henri Bontenbal\n",
      "Found 125 images for Henri Bontenbal\n",
      "Completed the extraction of 125 for politician Henri Bontenbal in 0 minutes and 5.77 seconds\n",
      "Fetching DuckDuckGo results for: Lilian Marijnissen\n",
      "Found 125 images for Lilian Marijnissen\n",
      "Completed the extraction of 125 for politician Lilian Marijnissen in 0 minutes and 5.83 seconds\n",
      "Fetching DuckDuckGo results for: Thierry Baudet\n",
      "Found 125 images for Thierry Baudet\n",
      "Completed the extraction of 125 for politician Thierry Baudet in 0 minutes and 5.85 seconds\n",
      "Fetching DuckDuckGo results for: Esther Ouwehand\n",
      "Found 125 images for Esther Ouwehand\n",
      "Completed the extraction of 125 for politician Esther Ouwehand in 0 minutes and 5.85 seconds\n",
      "Fetching DuckDuckGo results for: Mirjam Bikker\n",
      "Found 125 images for Mirjam Bikker\n",
      "Completed the extraction of 125 for politician Mirjam Bikker in 0 minutes and 5.72 seconds\n",
      "Fetching DuckDuckGo results for: Chris Stoffer\n",
      "Found 125 images for Chris Stoffer\n",
      "Completed the extraction of 125 for politician Chris Stoffer in 0 minutes and 5.83 seconds\n",
      "Fetching DuckDuckGo results for: Stephan van Baarle\n",
      "Found 125 images for Stephan van Baarle\n",
      "Completed the extraction of 125 for politician Stephan van Baarle in 0 minutes and 5.90 seconds\n",
      "Fetching DuckDuckGo results for: Laurens Dassen\n",
      "Found 125 images for Laurens Dassen\n",
      "Completed the extraction of 125 for politician Laurens Dassen in 0 minutes and 5.74 seconds\n",
      "Fetching DuckDuckGo results for: Joost Eerdmans\n",
      "Found 125 images for Joost Eerdmans\n",
      "Completed the extraction of 125 for politician Joost Eerdmans in 0 minutes and 5.82 seconds\n",
      "Fetching DuckDuckGo results for: Edson Olf\n",
      "Found 125 images for Edson Olf\n",
      "Completed the extraction of 125 for politician Edson Olf in 0 minutes and 5.72 seconds\n",
      "Fetching DuckDuckGo results for: Wybren van Haga\n",
      "Found 125 images for Wybren van Haga\n",
      "Completed the extraction of 125 for politician Wybren van Haga in 0 minutes and 5.78 seconds\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(nl_politicians_23):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    politician_array_ddg, image_links_ddg = get_image_links_ddg(p, num_results, headless=False)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    minutes, seconds = divmod(elapsed_time, 60)\n",
    "\n",
    "    print(f'Completed the extraction of {len(image_links_ddg)} for politician {p} in {int(minutes)} minutes and {seconds:.2f} seconds')\n",
    "    image_link_list.extend(image_links_ddg)\n",
    "    politician_list.extend(politician_array_ddg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e20515aa-8dbf-43cb-91c3-c97dd4dc5bcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2125 2125\n"
     ]
    }
   ],
   "source": [
    "print(len(politician_list), len(image_link_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e15d1cf2-b4e2-4105-9214-3ac2253ee409",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2120    https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse4.mm.bing.net%2Fth%2Fid%2FOIP.IDFGPCT8gqF3SZ575euiyQHaEv%3Fr%3D0%26pid%3DApi&f=1&ipt=aa6d3a15251b8f6af49531c06b7a59b43013d89561eabb8d3f4f9ea2ac2e79d7&ipo=images\n",
       "2121    https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse3.mm.bing.net%2Fth%2Fid%2FOIP.Mw7SLsbgGTrChRe-6uZXEQHaE7%3Fr%3D0%26pid%3DApi&f=1&ipt=5957ab3897e7502e113b3762fe134afee7ff97052245baadb6e21759f95f4d7f&ipo=images\n",
       "2122    https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse2.mm.bing.net%2Fth%2Fid%2FOIP.wcI1qCs2qoyOiDFaSszFlwHaEK%3Fr%3D0%26pid%3DApi&f=1&ipt=d8ced64a4bbbafe84ca34d45ef38a9096d7ec0167c9af6c98b52021a20ab16ec&ipo=images\n",
       "2123    https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse3.mm.bing.net%2Fth%2Fid%2FOIP.z4LWHHqmbNR_UT_Of72N8wHaFX%3Fr%3D0%26pid%3DApi&f=1&ipt=036dcadbf5e2a0250e2b4e49aeaeaa53a9918dc45aa7c0bd9f8bf5fa7b8e3703&ipo=images\n",
       "2124    https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse1.mm.bing.net%2Fth%2Fid%2FOIP.C-D7lld5rnvSPM1brExdFwHaEK%3Fr%3D0%26pid%3DApi&f=1&ipt=b7aae6e97995f0b5c9abb80809e37dc1a5aba3149107f05ae54e510fa4906bca&ipo=images\n",
       "Name: img_link, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ddg = pd.DataFrame({'politician': politician_list, 'img_link': image_link_list, 'engine': 'ddg'})\n",
    "df_ddg['img_link'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f431223-c2ca-4210-b95a-ecdf655fb5a3",
   "metadata": {},
   "source": [
    "#### Bing image links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffea533a-0641-47d4-869a-63b536bb13b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_link_list_bing = []\n",
    "politician_list_bing = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4dff91a-218b-4872-9ea0-50a9c068381b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1/3: Fetching Bing results for 'Geert Wilders'\n",
      "Successfully collected 125 images for 'Geert Wilders'\n",
      "Success: 125 images for Geert Wilders in 0m 10.9s\n",
      "Completed the extraction of 125 for politician Geert Wilders in 0 minutes and 10.90 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Frans Timmermans'\n",
      "Successfully collected 95 images for 'Frans Timmermans'\n",
      "Success: 95 images for Frans Timmermans in 0m 12.6s\n",
      "Completed the extraction of 95 for politician Frans Timmermans in 0 minutes and 12.63 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Dilan Yesilgöz'\n",
      "Successfully collected 116 images for 'Dilan Yesilgöz'\n",
      "Success: 116 images for Dilan Yesilgöz in 0m 12.5s\n",
      "Completed the extraction of 116 for politician Dilan Yesilgöz in 0 minutes and 12.52 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Pieter Omtzigt'\n",
      "Successfully collected 117 images for 'Pieter Omtzigt'\n",
      "Success: 117 images for Pieter Omtzigt in 0m 12.6s\n",
      "Completed the extraction of 117 for politician Pieter Omtzigt in 0 minutes and 12.59 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Rob Jetten'\n",
      "Successfully collected 108 images for 'Rob Jetten'\n",
      "Success: 108 images for Rob Jetten in 0m 12.8s\n",
      "Completed the extraction of 108 for politician Rob Jetten in 0 minutes and 12.79 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Caroline van der Plas'\n",
      "Successfully collected 125 images for 'Caroline van der Plas'\n",
      "Success: 125 images for Caroline van der Plas in 0m 10.5s\n",
      "Completed the extraction of 125 for politician Caroline van der Plas in 0 minutes and 10.53 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Henri Bontenbal'\n",
      "Successfully collected 96 images for 'Henri Bontenbal'\n",
      "Success: 96 images for Henri Bontenbal in 0m 12.9s\n",
      "Completed the extraction of 96 for politician Henri Bontenbal in 0 minutes and 12.92 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Lilian Marijnissen'\n",
      "Successfully collected 116 images for 'Lilian Marijnissen'\n",
      "Success: 116 images for Lilian Marijnissen in 0m 12.7s\n",
      "Completed the extraction of 116 for politician Lilian Marijnissen in 0 minutes and 12.71 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Thierry Baudet'\n",
      "Successfully collected 117 images for 'Thierry Baudet'\n",
      "Success: 117 images for Thierry Baudet in 0m 12.6s\n",
      "Completed the extraction of 117 for politician Thierry Baudet in 0 minutes and 12.56 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Esther Ouwehand'\n",
      "Successfully collected 117 images for 'Esther Ouwehand'\n",
      "Success: 117 images for Esther Ouwehand in 0m 12.5s\n",
      "Completed the extraction of 117 for politician Esther Ouwehand in 0 minutes and 12.46 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Mirjam Bikker'\n",
      "Successfully collected 96 images for 'Mirjam Bikker'\n",
      "Success: 96 images for Mirjam Bikker in 0m 12.3s\n",
      "Completed the extraction of 96 for politician Mirjam Bikker in 0 minutes and 12.30 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Chris Stoffer'\n",
      "Successfully collected 125 images for 'Chris Stoffer'\n",
      "Success: 125 images for Chris Stoffer in 0m 10.4s\n",
      "Completed the extraction of 125 for politician Chris Stoffer in 0 minutes and 10.39 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Stephan van Baarle'\n",
      "Successfully collected 125 images for 'Stephan van Baarle'\n",
      "Success: 125 images for Stephan van Baarle in 0m 10.4s\n",
      "Completed the extraction of 125 for politician Stephan van Baarle in 0 minutes and 10.42 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Laurens Dassen'\n",
      "Successfully collected 125 images for 'Laurens Dassen'\n",
      "Success: 125 images for Laurens Dassen in 0m 10.3s\n",
      "Completed the extraction of 125 for politician Laurens Dassen in 0 minutes and 10.28 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Joost Eerdmans'\n",
      "Successfully collected 125 images for 'Joost Eerdmans'\n",
      "Success: 125 images for Joost Eerdmans in 0m 10.4s\n",
      "Completed the extraction of 125 for politician Joost Eerdmans in 0 minutes and 10.35 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Edson Olf'\n",
      "Successfully collected 95 images for 'Edson Olf'\n",
      "Success: 95 images for Edson Olf in 0m 12.3s\n",
      "Completed the extraction of 95 for politician Edson Olf in 0 minutes and 12.34 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Wybren van Haga'\n",
      "Successfully collected 125 images for 'Wybren van Haga'\n",
      "Success: 125 images for Wybren van Haga in 0m 10.4s\n",
      "Completed the extraction of 125 for politician Wybren van Haga in 0 minutes and 10.45 seconds\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(nl_politicians_23):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try: \n",
    "        politician_array_bing, image_links_bing = get_image_links_bing(\n",
    "            p, \n",
    "            num_results, \n",
    "            headless=False\n",
    "        )\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        minutes, seconds = divmod(elapsed_time, 60)\n",
    "\n",
    "        if image_links_bing:\n",
    "            print(f\"Success: {len(image_links_bing)} images for {p} in {int(minutes)}m {seconds:.1f}s\")\n",
    "            image_link_list_bing.extend(image_links_bing)\n",
    "            politician_list_bing.extend(politician_array_bing)\n",
    "        else:\n",
    "            print(f\"Warning: No images found for {politician}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Critical error processing {p}: {str(e)}\")\n",
    "\n",
    "    print(f'Completed the extraction of {len(image_links_bing)} for politician {p} in {int(minutes)} minutes and {seconds:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be5dca72-0f10-4d74-8b8e-c152050a9d16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1948 1948\n"
     ]
    }
   ],
   "source": [
    "print(len(image_link_list_bing), len(politician_list_bing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d8f1a66-102f-4e04-9648-34e6d6cb3969",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1943    https://th.bing.com/th/id/OIP.V8s7PdcX0UgxZ-8-bdVLzAHaDn?w=290&h=171&c=7&r=0&o=7&dpr=2&pid=1.7&rm=3\n",
       "1944    https://th.bing.com/th/id/OIP.7XZKeH7-Z1twrtHTMNhdvQHaHa?w=146&h=180&c=7&r=0&o=7&dpr=2&pid=1.7&rm=3\n",
       "1945    https://th.bing.com/th/id/OIP.jrs3uJKuz5tMEvqyPNy9cwHaEK?w=260&h=180&c=7&r=0&o=7&dpr=2&pid=1.7&rm=3\n",
       "1946    https://th.bing.com/th/id/OIP._8dx833_KGVcSIFQ0lLzjAHaFY?w=200&h=180&c=7&r=0&o=7&dpr=2&pid=1.7&rm=3\n",
       "1947    https://th.bing.com/th/id/OIP.Mdc2joBke0gNzUqq2MFu9QHaEK?w=260&h=180&c=7&r=0&o=7&dpr=2&pid=1.7&rm=3\n",
       "Name: img_link, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bing = pd.DataFrame({'politician': politician_list_bing, 'img_link': image_link_list_bing, 'engine': 'bing'})\n",
    "df_bing['img_link'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d007932-ab66-4e1f-ac52-7bce9959312c",
   "metadata": {},
   "source": [
    "#### Ecosia image links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f06b12c-fe4b-4d65-a16f-1e61cef97cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_link_list_ecosia = []\n",
    "politician_list_ecosia = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b00a44c0-d103-48c2-bdff-0637e08ae648",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1/3: Fetching Ecosia results for 'Geert Wilders'\n",
      "Successfully collected 125 images for 'Geert Wilders'\n",
      "Success: 125 images for Geert Wilders in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Frans Timmermans'\n",
      "Successfully collected 125 images for 'Frans Timmermans'\n",
      "Success: 125 images for Frans Timmermans in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Dilan Yesilgöz'\n",
      "Successfully collected 125 images for 'Dilan Yesilgöz'\n",
      "Success: 125 images for Dilan Yesilgöz in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Pieter Omtzigt'\n",
      "Successfully collected 125 images for 'Pieter Omtzigt'\n",
      "Success: 125 images for Pieter Omtzigt in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Rob Jetten'\n",
      "Successfully collected 125 images for 'Rob Jetten'\n",
      "Success: 125 images for Rob Jetten in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Caroline van der Plas'\n",
      "Successfully collected 125 images for 'Caroline van der Plas'\n",
      "Success: 125 images for Caroline van der Plas in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Henri Bontenbal'\n",
      "Successfully collected 125 images for 'Henri Bontenbal'\n",
      "Success: 125 images for Henri Bontenbal in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Lilian Marijnissen'\n",
      "Successfully collected 125 images for 'Lilian Marijnissen'\n",
      "Success: 125 images for Lilian Marijnissen in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Thierry Baudet'\n",
      "Successfully collected 125 images for 'Thierry Baudet'\n",
      "Success: 125 images for Thierry Baudet in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Esther Ouwehand'\n",
      "Successfully collected 125 images for 'Esther Ouwehand'\n",
      "Success: 125 images for Esther Ouwehand in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Mirjam Bikker'\n",
      "Successfully collected 125 images for 'Mirjam Bikker'\n",
      "Success: 125 images for Mirjam Bikker in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Chris Stoffer'\n",
      "Successfully collected 125 images for 'Chris Stoffer'\n",
      "Success: 125 images for Chris Stoffer in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Stephan van Baarle'\n",
      "Successfully collected 125 images for 'Stephan van Baarle'\n",
      "Success: 125 images for Stephan van Baarle in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Laurens Dassen'\n",
      "Successfully collected 125 images for 'Laurens Dassen'\n",
      "Success: 125 images for Laurens Dassen in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Joost Eerdmans'\n",
      "Successfully collected 125 images for 'Joost Eerdmans'\n",
      "Success: 125 images for Joost Eerdmans in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Edson Olf'\n",
      "Successfully collected 125 images for 'Edson Olf'\n",
      "Success: 125 images for Edson Olf in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Wybren van Haga'\n",
      "Successfully collected 125 images for 'Wybren van Haga'\n",
      "Success: 125 images for Wybren van Haga in 0m 10.4s\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(nl_politicians_23):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "            politician_array_ecosia, image_links_ecosia = get_image_links_ecosia(\n",
    "                p, \n",
    "                num_results,\n",
    "                headless=False\n",
    "            )\n",
    "            \n",
    "            elapsed = time.time() - start_time\n",
    "            mins, secs = divmod(elapsed, 60)\n",
    "            \n",
    "            if image_links_ecosia:\n",
    "                print(f\"Success: {len(image_links_ecosia)} images for {p} in {int(minutes)}m {seconds:.1f}s\")\n",
    "                image_link_list_ecosia.extend(image_links_ecosia)\n",
    "                politician_list_ecosia.extend(politician_array_ecosia)\n",
    "            else:\n",
    "                print(f\"Warning: No images found for {p}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Critical error processing {p}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43ce2bd3-2ed1-4f88-b6b2-312bb5f185f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2125 2125\n"
     ]
    }
   ],
   "source": [
    "print(len(image_link_list_ecosia), len(politician_list_ecosia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0e04d97-fa3d-4da5-81a8-d1dc4dcd8f26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2120    https://images.nieuwrechts.nl/artikel-foto/99d8c22c5772b69f318360755ec3b6f9/van-haga.jpg\n",
       "2121                                   https://cdn.nos.nl/image/2021/07/02/759442/2560x1440a.jpg\n",
       "2122         https://www.linda.nl/lindanl-assets/uploads/2021/05/06161326/Van-Haga-1800x1012.jpg\n",
       "2123                                        https://i.ytimg.com/vi/hWgDhScdmvk/maxresdefault.jpg\n",
       "2124               https://lookaside.fbsbx.com/lookaside/crawler/media/?media_id=729099682360713\n",
       "Name: img_link, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ecosia = pd.DataFrame({'politician': politician_list_ecosia, 'img_link': image_link_list_ecosia, 'engine': 'ecosia'})\n",
    "df_ecosia['img_link'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb47d729",
   "metadata": {},
   "source": [
    "### Combine DuckDuckGo, Bing and Ecosia dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ef033a7-9420-4c72-afe0-777b0d4df345",
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_imgref_df = pd.concat([df_ecosia, df_bing, df_ddg], axis=0, ignore_index=True)\n",
    "nl_imgref_df = nl_imgref_df.sort_values(by=['politician', 'engine'])\n",
    "nl_imgref_df = nl_imgref_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5074ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_imgref_df.to_pickle('datasets/train_test/NL/nl_searchengine_imgref_results.pkl')\n",
    "nl_imgref_df.to_csv('datasets/train_test/NL/nl_searchengine_imgref_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbb47b7",
   "metadata": {},
   "source": [
    "### Collect training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfec4a7",
   "metadata": {},
   "source": [
    "Insightface is applied to the full training image. Thereby, only the faces are cut-out and stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae07db59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wiesruyters/miniconda3/envs/multimodalmedia/lib/python3.12/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:118: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CoreMLExecutionProvider, AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/wiesruyters/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/wiesruyters/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/wiesruyters/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/wiesruyters/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/wiesruyters/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "app = FaceAnalysis(\n",
    "    name='buffalo_l',\n",
    "    providers=['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    ")\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586a957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filename(url, p, face_index):\n",
    "    url_hash = hashlib.md5(url.encode()).hexdigest()[:8]\n",
    "    return f\"{url_hash}_{p}_{face_index}.jpg\"\n",
    "\n",
    "def download_image(url, timeout=15):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, stream=True, timeout=timeout)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Verify that the ref leads to an image\n",
    "        if 'image' not in response.headers.get('Content-Type', ''):\n",
    "            raise ValueError(\"Oops... no image found here!\")\n",
    "            \n",
    "        image = np.asarray(bytearray(response.content), dtype=\"uint8\")\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        if image is None:\n",
    "            raise ValueError(\"Failed to decode image\")\n",
    "            \n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {url[:50]}...: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_images(df, output_base):\n",
    "    pbar = tqdm(df.iterrows(), total=len(df), desc=\"Processing training images\")\n",
    "    \n",
    "    for idx, row in pbar:\n",
    "        politician = row['politician']\n",
    "        img_url = row['img_link']\n",
    "     \n",
    "        politician_safe = \"\".join(c if c.isalnum() else \"_\" for c in politician)\n",
    "        politician_dir = os.path.join(output_base, politician_safe)\n",
    "        os.makedirs(politician_dir, exist_ok=True)\n",
    "        \n",
    "        # Save image with retry\n",
    "        img = None\n",
    "        for attempt in range(3): # Attempts\n",
    "            img = download_image(img_url)\n",
    "            if img is not None:\n",
    "                break\n",
    "            time.sleep(1)\n",
    "        \n",
    "        if img is None:\n",
    "            continue\n",
    "        \n",
    "        # Detect faces using the Insightface app (confidence threshold)\n",
    "        faces = app.get(img)\n",
    "        \n",
    "        # Filter\n",
    "        faces = [face for face in faces if face.det_score > 0.6]\n",
    "        \n",
    "        if not faces:\n",
    "            continue\n",
    "        \n",
    "        # Process faces\n",
    "        for i, face in enumerate(faces):\n",
    "            # Bounding box\n",
    "            bbox = face.bbox.astype(int)\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            \n",
    "            # Dynamic padding based on face size\n",
    "            padding_factor = min(0.3, 100/max(x2-x1, y2-y1))  # Slightly larger pad for small faces\n",
    "            h, w = y2 - y1, x2 - x1\n",
    "            x1 = max(0, x1 - int(padding_factor * w))\n",
    "            y1 = max(0, y1 - int(padding_factor * h))\n",
    "            x2 = min(img.shape[1], x2 + int(padding_factor * w))\n",
    "            y2 = min(img.shape[0], y2 + int(padding_factor * h))\n",
    "            \n",
    "            # Crop \n",
    "            face_crop = img[y1:y2, x1:x2]\n",
    "            if face_crop.size == 0:\n",
    "                continue\n",
    "                \n",
    "            # Generate filename and save\n",
    "            face_filename = generate_filename(img_url, politician, i)\n",
    "            save_path = os.path.join(politician_dir, face_filename)\n",
    "            \n",
    "            try:\n",
    "                # Save\n",
    "                cv2.imwrite(save_path, face_crop, [int(cv2.IMWRITE_JPEG_QUALITY), 90])\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving {save_path}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecaa12e",
   "metadata": {},
   "source": [
    "NOTE: this function is run only once. After it ran, and the facial images are collected, a manual correction is applied. With drag-and-drop, the image samples are put in the folders that contain the right label (here: politician name). <br>\n",
    "DO NOT RUN THIS FUNCTION; the faces are already collected and corrected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "becfadc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process_images(, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f1ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embedding_on_the_wall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
