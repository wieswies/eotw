{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0c00e1-e081-44f5-a9d6-18c806028298",
   "metadata": {},
   "source": [
    "#### Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2697209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wiesruyters/miniconda3/envs/multimodalmedia/lib/python3.12/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "# For necessary data processing and calculations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For reading and writing files\n",
    "import json\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import io\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "\n",
    "# For image processing\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import face_recognition\n",
    "import dlib\n",
    "import cv2\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# For face-embedding calculation\n",
    "from keras_facenet import FaceNet as FN\n",
    "\n",
    "# For machine learning\n",
    "import tensorflow as tf\n",
    "\n",
    "# For web scraping\n",
    "import html\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# For tracking programming progress\n",
    "from tqdm.notebook import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98d05ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b335075-d57a-4dd8-839c-8c64b9040e5e",
   "metadata": {},
   "source": [
    "# UK data collection for train/test image scraping\n",
    "This notebook contains the scraping method that obtains image references from three different search engines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617ee6da-662b-4138-a5ba-5f718d983fb7",
   "metadata": {},
   "source": [
    "##### Set-up web driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "541f17f9-f966-42dc-816b-3a7cc8f9ec46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wd = webdriver.Firefox()\n",
    "wd.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22803d89-9baa-42e9-8460-2695bc3b1211",
   "metadata": {},
   "source": [
    "### Define methods \n",
    "get_image_links_x: use the automated web browser to retrieve the image links that resulted from the search query <br>\n",
    "download_image: go over the retrieved urls and download the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5af2cbe1-cb5e-40d4-a379-9627abdbbe2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_links_ddg(search_query, num_results, headless=True):\n",
    "    \"\"\"\n",
    "    DuckDuckGo image scraper\n",
    "    \"\"\"\n",
    "    ddg_search_url = f'https://duckduckgo.com/?q={search_query}&iax=images&ia=images'\n",
    "    \n",
    "    options = webdriver.SafariOptions()\n",
    "    if headless:\n",
    "        options.add_argument('--headless')\n",
    "    \n",
    "    driver = webdriver.Safari(options=options)\n",
    "    \n",
    "    try:\n",
    "        print(f\"Fetching DuckDuckGo results for: {search_query}\")\n",
    "        driver.get(ddg_search_url)\n",
    "        time.sleep(2) \n",
    "        \n",
    "        # Scroll\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        scroll_attempts = 0\n",
    "        \n",
    "        while scroll_attempts < 5:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # Check if bottom is reached or enough image urls are obtained\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "            \n",
    "            # Check for images\n",
    "            image_elements = driver.find_elements(By.CSS_SELECTOR, 'img[data-src], img[src*=\"external-content.duckduckgo.com\"]')\n",
    "            if len(image_elements) >= num_results:\n",
    "                break\n",
    "            scroll_attempts += 1\n",
    "        \n",
    "        # Find all image elements\n",
    "        image_elements = driver.find_elements(By.CSS_SELECTOR, 'img[data-src], img[src*=\"external-content.duckduckgo.com\"]')\n",
    "        \n",
    "        # Extract both src and data-src attr\n",
    "        links = []\n",
    "        for img in image_elements[:num_results]:\n",
    "            src = img.get_attribute('src') or img.get_attribute('data-src')\n",
    "            if src:\n",
    "                if src.startswith('//'):\n",
    "                    src = 'https:' + src\n",
    "                links.append(src)\n",
    "        \n",
    "        politician_array = [search_query] * len(links)\n",
    "        \n",
    "        print(f\"Found {len(links)} images for {search_query}\")\n",
    "        return politician_array, links\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while scraping DuckDuckGo for {search_query}: {str(e)}\")\n",
    "        return [search_query], []\n",
    "\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "462a3e37-68a8-4cc6-b698-1e474b7e6417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_links_bing(search_query, num_results, max_retries=3, headless=True):\n",
    "    \"\"\"\n",
    "    Bing image scraper \n",
    "    \"\"\"\n",
    "    bing_search_url = f'https://www.bing.com/images/search?q={search_query.replace(\" \", \"+\")}'\n",
    "\n",
    "    options = webdriver.SafariOptions()\n",
    "    if headless:\n",
    "        options.add_argument('--headless')\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        driver = None\n",
    "        try:\n",
    "            driver = webdriver.Safari(options=options)\n",
    "            driver.get(bing_search_url)\n",
    "            print(f\"Attempt {attempt + 1}/{max_retries}: Fetching Bing results for '{search_query}'\")\n",
    "            \n",
    "            time.sleep(2)\n",
    "            \n",
    "            # Scroll\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            images_collected = 0\n",
    "            scroll_attempts = 0\n",
    "            \n",
    "            while scroll_attempts < 5 and images_collected < num_results:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(2)\n",
    "                \n",
    "                # Check if bottom is reached or enough image urls are obtained\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "                \n",
    "                # Find all image elements\n",
    "                image_elements = driver.find_elements(\n",
    "                    By.CSS_SELECTOR, \n",
    "                    'img.mimg:not([src^=\"data:\"])'\n",
    "                )\n",
    "                images_collected = len(image_elements)\n",
    "                scroll_attempts += 1\n",
    "            \n",
    "            # Extract image URLs\n",
    "            image_elements = driver.find_elements(\n",
    "                By.CSS_SELECTOR, \n",
    "                'img.mimg[src]:not([src^=\"data:\"])'\n",
    "            )\n",
    "            \n",
    "            links = []\n",
    "            for img in image_elements[:num_results]:\n",
    "                src = img.get_attribute('src')\n",
    "                if src and not src.startswith('data:'):\n",
    "                    # Cover for relative URLs\n",
    "                    if src.startswith('/'):\n",
    "                        src = f'https://www.bing.com{src}'\n",
    "                    links.append(src)\n",
    "            \n",
    "            if not links:\n",
    "                print(f\"No image links found for '{search_query}' (attempt {attempt + 1})\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(5 * (attempt + 1))\n",
    "                    continue\n",
    "                return [search_query], []\n",
    "            \n",
    "            politician_array = [search_query] * len(links)\n",
    "            print(f\"Successfully collected {len(links)} images for '{search_query}'\")\n",
    "            return politician_array, links\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed for '{search_query}': {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = 5 * (attempt + 1)\n",
    "                print(f\"Waiting {wait_time} seconds before retry...\")\n",
    "                time.sleep(wait_time)\n",
    "            \n",
    "        finally:\n",
    "            if driver:\n",
    "                driver.quit()\n",
    "    \n",
    "    return [search_query], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6788689b-7f83-4e35-bd93-10c8588fab12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_links_ecosia(search_query, num_results, max_retries=3, headless=True):\n",
    "    \"\"\"\n",
    "    Ecosia image scraper\n",
    "    \"\"\"\n",
    "    ecosia_search_url = f'https://www.ecosia.org/images?q={search_query.replace(\" \", \"+\")}'\n",
    "    \n",
    "    options = webdriver.SafariOptions()\n",
    "    if headless:\n",
    "        options.add_argument('--headless')\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        driver = None\n",
    "        try:\n",
    "            driver = webdriver.Safari(options=options)\n",
    "            print(f\"Attempt {attempt + 1}/{max_retries}: Fetching Ecosia results for '{search_query}'\")\n",
    "            \n",
    "            driver.set_page_load_timeout(30)\n",
    "            driver.get(ecosia_search_url)\n",
    "            \n",
    "            # Wait\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \".image-result__link-wrapper\"))\n",
    "            )\n",
    "            \n",
    "            # Scroll\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            images_collected = 0\n",
    "            scroll_attempts = 0\n",
    "            \n",
    "            while scroll_attempts < 5 and images_collected < num_results:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(2)\n",
    "                \n",
    "                # Check if bottom is reached\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "                \n",
    "                # Count the number of images collected\n",
    "                image_elements = driver.find_elements(By.CSS_SELECTOR, '.image-result__link-wrapper')\n",
    "                images_collected = len(image_elements)\n",
    "                scroll_attempts += 1\n",
    "            \n",
    "            # Extract both href and src attributes\n",
    "            image_wrappers = driver.find_elements(\n",
    "                By.CSS_SELECTOR, \n",
    "                '.image-result__link-wrapper'\n",
    "            )\n",
    "            \n",
    "            links = []\n",
    "            for wrapper in image_wrappers[:num_results]:\n",
    "                try:\n",
    "                    # First: href\n",
    "                    link = wrapper.find_element(By.CSS_SELECTOR, 'a.image-result__link')\n",
    "                    href = link.get_attribute('href')\n",
    "                    \n",
    "                    # Fallback: src\n",
    "                    if not href:\n",
    "                        img = wrapper.find_element(By.CSS_SELECTOR, 'img.image-result__image')\n",
    "                        href = img.get_attribute('src')\n",
    "                    \n",
    "                    if href:\n",
    "                        links.append(href)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Couldn't extract link from one result: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            if not links:\n",
    "                print(f\"No image links found for '{search_query}' (attempt {attempt + 1})\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(5 * (attempt + 1))\n",
    "                    continue\n",
    "                return [search_query], []\n",
    "            \n",
    "            politician_array = [search_query] * len(links)\n",
    "            print(f\"Successfully collected {len(links)} images for '{search_query}'\")\n",
    "            return politician_array, links\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed for '{search_query}': {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = 5 * (attempt + 1)\n",
    "                print(f\"Waiting {wait_time} seconds before retry...\")\n",
    "                time.sleep(wait_time)\n",
    "            \n",
    "        finally:\n",
    "            if driver:\n",
    "                driver.quit()\n",
    "    \n",
    "    return [search_query], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7de667-aac5-4744-a1e7-3facb9807a3a",
   "metadata": {},
   "source": [
    "### Create database with image links\n",
    "Create a list of politician names and set a limit on the number of image links to be extracted. <br>\n",
    "For the UK, this list is based on: https://en.wikipedia.org/wiki/2024_United_Kingdom_general_election\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a4df4be-c8af-49b2-ab72-00ee341d27ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uk_politicians_24 = [   # Party name / #seats\n",
    "    'Keir Starmer',     # Labour / 411 \n",
    "    'Rishi Sunak',      # Conservative / 121\n",
    "    'Nigel Farage',     # Reform UK / 5\n",
    "    'Ed Davey',         # Liberal Democrats / 72\n",
    "    'Carla Denyer',     # Green Party of England and Wales / 4\n",
    "    'Adrian Ramsay',    # Green Party of England and Wales / 4\n",
    "    'John Swinney',     # Scottish National Party / 9\n",
    "    'Mary Lou McDonald',# Sinn Féin / 7\n",
    "    'George Galloway',  # Workers Party / 0 (new)\n",
    "    'Rhun ap Iorwerth', # Plaid Cymru / 4\n",
    "    'Gavin Robinson',   # Democratic Unionist / 5\n",
    "    'Naomi Long',       # Alliance / 1\n",
    "    'Doug Beattie',     # Ulster Unionist / 1\n",
    "    'Patrick Harvie',   # Scottish Greens / 0\n",
    "    'Lorna Slater',     # Scottish Greens / 0\n",
    "    'Colum Eastwood',   # Social Democratic & Labour / 2\n",
    "    'Jim Allister'      # Tradiitional Unionist Vote / 1\n",
    "    ]\n",
    "\n",
    "num_results = 125\n",
    "image_link_list = []\n",
    "politician_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95bcccf-e72b-49b3-8d7d-273469651dba",
   "metadata": {},
   "source": [
    "#### DuckDuckGo image links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4563b17c-232b-4e41-b091-f72536a41861",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching DuckDuckGo results for: Keir Starmer\n",
      "Found 125 images for Keir Starmer\n",
      "Completed the extraction of 125 for politician Keir Starmer in 0 minutes and 5.63 seconds\n",
      "Fetching DuckDuckGo results for: Rishi Sunak\n",
      "Found 125 images for Rishi Sunak\n",
      "Completed the extraction of 125 for politician Rishi Sunak in 0 minutes and 5.56 seconds\n",
      "Fetching DuckDuckGo results for: Nigel Farage\n",
      "Found 125 images for Nigel Farage\n",
      "Completed the extraction of 125 for politician Nigel Farage in 0 minutes and 5.63 seconds\n",
      "Fetching DuckDuckGo results for: Ed Davey\n",
      "Found 125 images for Ed Davey\n",
      "Completed the extraction of 125 for politician Ed Davey in 0 minutes and 5.61 seconds\n",
      "Fetching DuckDuckGo results for: Carla Denyer\n",
      "Found 125 images for Carla Denyer\n",
      "Completed the extraction of 125 for politician Carla Denyer in 0 minutes and 5.59 seconds\n",
      "Fetching DuckDuckGo results for: Adrian Ramsay\n",
      "Found 125 images for Adrian Ramsay\n",
      "Completed the extraction of 125 for politician Adrian Ramsay in 0 minutes and 5.62 seconds\n",
      "Fetching DuckDuckGo results for: John Swinney\n",
      "Found 125 images for John Swinney\n",
      "Completed the extraction of 125 for politician John Swinney in 0 minutes and 5.65 seconds\n",
      "Fetching DuckDuckGo results for: Mary Lou McDonald\n",
      "Found 125 images for Mary Lou McDonald\n",
      "Completed the extraction of 125 for politician Mary Lou McDonald in 0 minutes and 5.62 seconds\n",
      "Fetching DuckDuckGo results for: George Galloway\n",
      "Found 125 images for George Galloway\n",
      "Completed the extraction of 125 for politician George Galloway in 0 minutes and 5.67 seconds\n",
      "Fetching DuckDuckGo results for: Rhun ap Iorwerth\n",
      "Found 125 images for Rhun ap Iorwerth\n",
      "Completed the extraction of 125 for politician Rhun ap Iorwerth in 0 minutes and 5.63 seconds\n",
      "Fetching DuckDuckGo results for: Gavin Robinson\n",
      "Found 125 images for Gavin Robinson\n",
      "Completed the extraction of 125 for politician Gavin Robinson in 0 minutes and 5.62 seconds\n",
      "Fetching DuckDuckGo results for: Naomi Long\n",
      "Found 125 images for Naomi Long\n",
      "Completed the extraction of 125 for politician Naomi Long in 0 minutes and 5.62 seconds\n",
      "Fetching DuckDuckGo results for: Doug Beattie\n",
      "Found 125 images for Doug Beattie\n",
      "Completed the extraction of 125 for politician Doug Beattie in 0 minutes and 5.63 seconds\n",
      "Fetching DuckDuckGo results for: Patrick Harvie\n",
      "Found 125 images for Patrick Harvie\n",
      "Completed the extraction of 125 for politician Patrick Harvie in 0 minutes and 5.63 seconds\n",
      "Fetching DuckDuckGo results for: Lorna Slater\n",
      "Found 125 images for Lorna Slater\n",
      "Completed the extraction of 125 for politician Lorna Slater in 0 minutes and 5.62 seconds\n",
      "Fetching DuckDuckGo results for: Colum Eastwood\n",
      "Found 125 images for Colum Eastwood\n",
      "Completed the extraction of 125 for politician Colum Eastwood in 0 minutes and 5.61 seconds\n",
      "Fetching DuckDuckGo results for: Jim Allister\n",
      "Found 125 images for Jim Allister\n",
      "Completed the extraction of 125 for politician Jim Allister in 0 minutes and 5.63 seconds\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(uk_politicians_24):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    politician_array_ddg, image_links_ddg = get_image_links_ddg(p, num_results, headless=False)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    minutes, seconds = divmod(elapsed_time, 60)\n",
    "\n",
    "    print(f'Completed the extraction of {len(image_links_ddg)} for politician {p} in {int(minutes)} minutes and {seconds:.2f} seconds')\n",
    "    image_link_list.extend(image_links_ddg)\n",
    "    politician_list.extend(politician_array_ddg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e20515aa-8dbf-43cb-91c3-c97dd4dc5bcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2125 2125\n"
     ]
    }
   ],
   "source": [
    "print(len(politician_list), len(image_link_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e15d1cf2-b4e2-4105-9214-3ac2253ee409",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2120    https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse4.mm.bing.net%2Fth%2Fid%2FOIP.tkI6RR-3JKkzhB7Gdp2O6AHaEM%3Fpid%3DApi&f=1&ipt=89abd46d271323ae4748d347037aab5e463efccbb51d33886b829c4dbff33128&ipo=images\n",
       "2121    https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse2.mm.bing.net%2Fth%2Fid%2FOIP.vanofBJQhNrJfQLjVpUfvwHaFj%3Fpid%3DApi&f=1&ipt=bcb97ef62a9fca75fb1657ac6911bc3d9381724112c7b4b1333572d935cf11cb&ipo=images\n",
       "2122    https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse1.mm.bing.net%2Fth%2Fid%2FOIP.CbAua9lU7aVBZ-4CRIG5YAHaJ4%3Fpid%3DApi&f=1&ipt=e371835a42090f07f0c17c416a297010da6b30d16f64c7cf05587e68a8cea824&ipo=images\n",
       "2123    https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse4.mm.bing.net%2Fth%2Fid%2FOIP.785cSPtZs2i8l9Lk9lWJiwHaFb%3Fpid%3DApi&f=1&ipt=b7bd8144e50a310298fe222e8ea397fb06fc3d966ce1c296b2cb48f37f1ff4d1&ipo=images\n",
       "2124    https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse4.mm.bing.net%2Fth%2Fid%2FOIP.8oDz5HZsv2ZwA7HUToq8QQHaFc%3Fpid%3DApi&f=1&ipt=f8b78b3dbbd3b9ba2e769e68b688c39785d4ca94c4b8c2b4f096e460f85615ea&ipo=images\n",
       "Name: img_link, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ddg = pd.DataFrame({'politician': politician_list, 'img_link': image_link_list, 'engine': 'ddg'})\n",
    "df_ddg['img_link'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f431223-c2ca-4210-b95a-ecdf655fb5a3",
   "metadata": {},
   "source": [
    "#### Bing image links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffea533a-0641-47d4-869a-63b536bb13b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_link_list_bing = []\n",
    "politician_list_bing = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dff91a-218b-4872-9ea0-50a9c068381b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1/3: Fetching Bing results for 'Keir Starmer'\n",
      "Successfully collected 125 images for 'Keir Starmer'\n",
      "Success: 125 images for Keir Starmer in 0m 10.4s\n",
      "Completed the extraction of 125 for politician Keir Starmer in 0 minutes and 10.37 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Rishi Sunak'\n",
      "Successfully collected 125 images for 'Rishi Sunak'\n",
      "Success: 125 images for Rishi Sunak in 0m 10.3s\n",
      "Completed the extraction of 125 for politician Rishi Sunak in 0 minutes and 10.31 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Nigel Farage'\n",
      "Successfully collected 125 images for 'Nigel Farage'\n",
      "Success: 125 images for Nigel Farage in 0m 10.5s\n",
      "Completed the extraction of 125 for politician Nigel Farage in 0 minutes and 10.52 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Ed Davey'\n",
      "Successfully collected 125 images for 'Ed Davey'\n",
      "Success: 125 images for Ed Davey in 0m 10.3s\n",
      "Completed the extraction of 125 for politician Ed Davey in 0 minutes and 10.33 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Carla Denyer'\n",
      "Successfully collected 116 images for 'Carla Denyer'\n",
      "Success: 116 images for Carla Denyer in 0m 12.0s\n",
      "Completed the extraction of 116 for politician Carla Denyer in 0 minutes and 11.98 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Adrian Ramsay'\n",
      "Successfully collected 96 images for 'Adrian Ramsay'\n",
      "Success: 96 images for Adrian Ramsay in 0m 12.1s\n",
      "Completed the extraction of 96 for politician Adrian Ramsay in 0 minutes and 12.11 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'John Swinney'\n",
      "Successfully collected 125 images for 'John Swinney'\n",
      "Success: 125 images for John Swinney in 0m 10.5s\n",
      "Completed the extraction of 125 for politician John Swinney in 0 minutes and 10.53 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Mary Lou McDonald'\n",
      "Successfully collected 125 images for 'Mary Lou McDonald'\n",
      "Success: 125 images for Mary Lou McDonald in 0m 10.6s\n",
      "Completed the extraction of 125 for politician Mary Lou McDonald in 0 minutes and 10.64 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'George Galloway'\n",
      "Successfully collected 125 images for 'George Galloway'\n",
      "Success: 125 images for George Galloway in 0m 10.1s\n",
      "Completed the extraction of 125 for politician George Galloway in 0 minutes and 10.13 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Rhun ap Iorwerth'\n",
      "Successfully collected 125 images for 'Rhun ap Iorwerth'\n",
      "Success: 125 images for Rhun ap Iorwerth in 0m 10.2s\n",
      "Completed the extraction of 125 for politician Rhun ap Iorwerth in 0 minutes and 10.21 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Gavin Robinson'\n",
      "Successfully collected 125 images for 'Gavin Robinson'\n",
      "Success: 125 images for Gavin Robinson in 0m 10.4s\n",
      "Completed the extraction of 125 for politician Gavin Robinson in 0 minutes and 10.38 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Naomi Long'\n",
      "Successfully collected 125 images for 'Naomi Long'\n",
      "Success: 125 images for Naomi Long in 0m 11.0s\n",
      "Completed the extraction of 125 for politician Naomi Long in 0 minutes and 10.99 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Doug Beattie'\n",
      "Successfully collected 96 images for 'Doug Beattie'\n",
      "Success: 96 images for Doug Beattie in 0m 12.5s\n",
      "Completed the extraction of 96 for politician Doug Beattie in 0 minutes and 12.53 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Patrick Harvie'\n",
      "Successfully collected 125 images for 'Patrick Harvie'\n",
      "Success: 125 images for Patrick Harvie in 0m 10.3s\n",
      "Completed the extraction of 125 for politician Patrick Harvie in 0 minutes and 10.33 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Lorna Slater'\n",
      "Successfully collected 125 images for 'Lorna Slater'\n",
      "Success: 125 images for Lorna Slater in 0m 10.7s\n",
      "Completed the extraction of 125 for politician Lorna Slater in 0 minutes and 10.69 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Colum Eastwood'\n",
      "Successfully collected 117 images for 'Colum Eastwood'\n",
      "Success: 117 images for Colum Eastwood in 0m 12.5s\n",
      "Completed the extraction of 117 for politician Colum Eastwood in 0 minutes and 12.48 seconds\n",
      "Attempt 1/3: Fetching Bing results for 'Jim Allister'\n",
      "Successfully collected 125 images for 'Jim Allister'\n",
      "Success: 125 images for Jim Allister in 0m 10.4s\n",
      "Completed the extraction of 125 for politician Jim Allister in 0 minutes and 10.44 seconds\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(uk_politicians_24):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try: \n",
    "        politician_array_bing, image_links_bing = get_image_links_bing(\n",
    "            p, \n",
    "            num_results, \n",
    "            headless=False\n",
    "        )\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        minutes, seconds = divmod(elapsed_time, 60)\n",
    "\n",
    "        if image_links_bing:\n",
    "            print(f\"Success: {len(image_links_bing)} images for {p} in {int(minutes)}m {seconds:.1f}s\")\n",
    "            image_link_list_bing.extend(image_links_bing)\n",
    "            politician_list_bing.extend(politician_array_bing)\n",
    "        else:\n",
    "            print(f\"Warning: No images found for {politician}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Critical error processing {p}: {str(e)}\")\n",
    "\n",
    "    print(f'Completed the extraction of {len(image_links_bing)} for politician {p} in {int(minutes)} minutes and {seconds:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be5dca72-0f10-4d74-8b8e-c152050a9d16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2050 2050\n"
     ]
    }
   ],
   "source": [
    "print(len(image_link_list_bing), len(politician_list_bing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d8f1a66-102f-4e04-9648-34e6d6cb3969",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2045    https://th.bing.com/th/id/OIP.lJSznue74RkLp3ZtLAfGQgHaFc?w=233&h=180&c=7&r=0&o=7&dpr=2&pid=1.7&rm=3\n",
       "2046    https://th.bing.com/th/id/OIP.0yua4KKGazN8zPJHTl-aGgHaEK?w=274&h=180&c=7&r=0&o=7&dpr=2&pid=1.7&rm=3\n",
       "2047    https://th.bing.com/th/id/OIP.Tp_KgxyxCdr33NYoLR0cEgHaL4?w=115&h=180&c=7&r=0&o=7&dpr=2&pid=1.7&rm=3\n",
       "2048    https://th.bing.com/th/id/OIP.wwBNFiaYvqM4r97exJbMrgHaF2?w=192&h=180&c=7&r=0&o=7&dpr=2&pid=1.7&rm=3\n",
       "2049    https://th.bing.com/th/id/OIP.1rNWIlLtumm2FF87MWghOQHaEK?w=272&h=180&c=7&r=0&o=7&dpr=2&pid=1.7&rm=3\n",
       "Name: img_link, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bing = pd.DataFrame({'politician': politician_list_bing, 'img_link': image_link_list_bing, 'engine': 'bing'})\n",
    "df_bing['img_link'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d007932-ab66-4e1f-ac52-7bce9959312c",
   "metadata": {},
   "source": [
    "#### Ecosia image links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f06b12c-fe4b-4d65-a16f-1e61cef97cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_link_list_ecosia = []\n",
    "politician_list_ecosia = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b00a44c0-d103-48c2-bdff-0637e08ae648",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1/3: Fetching Ecosia results for 'Keir Starmer'\n",
      "Successfully collected 125 images for 'Keir Starmer'\n",
      "Success: 125 images for Keir Starmer in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Rishi Sunak'\n",
      "Successfully collected 125 images for 'Rishi Sunak'\n",
      "Success: 125 images for Rishi Sunak in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Nigel Farage'\n",
      "Successfully collected 125 images for 'Nigel Farage'\n",
      "Success: 125 images for Nigel Farage in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Ed Davey'\n",
      "Successfully collected 125 images for 'Ed Davey'\n",
      "Success: 125 images for Ed Davey in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Carla Denyer'\n",
      "Successfully collected 125 images for 'Carla Denyer'\n",
      "Success: 125 images for Carla Denyer in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Adrian Ramsay'\n",
      "Successfully collected 125 images for 'Adrian Ramsay'\n",
      "Success: 125 images for Adrian Ramsay in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'John Swinney'\n",
      "Successfully collected 125 images for 'John Swinney'\n",
      "Success: 125 images for John Swinney in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Mary Lou McDonald'\n",
      "Successfully collected 125 images for 'Mary Lou McDonald'\n",
      "Success: 125 images for Mary Lou McDonald in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'George Galloway'\n",
      "Successfully collected 125 images for 'George Galloway'\n",
      "Success: 125 images for George Galloway in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Rhun ap Iorwerth'\n",
      "Successfully collected 125 images for 'Rhun ap Iorwerth'\n",
      "Success: 125 images for Rhun ap Iorwerth in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Gavin Robinson'\n",
      "Successfully collected 125 images for 'Gavin Robinson'\n",
      "Success: 125 images for Gavin Robinson in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Naomi Long'\n",
      "Successfully collected 125 images for 'Naomi Long'\n",
      "Success: 125 images for Naomi Long in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Doug Beattie'\n",
      "Successfully collected 125 images for 'Doug Beattie'\n",
      "Success: 125 images for Doug Beattie in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Patrick Harvie'\n",
      "Successfully collected 125 images for 'Patrick Harvie'\n",
      "Success: 125 images for Patrick Harvie in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Lorna Slater'\n",
      "Successfully collected 125 images for 'Lorna Slater'\n",
      "Success: 125 images for Lorna Slater in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Colum Eastwood'\n",
      "Successfully collected 125 images for 'Colum Eastwood'\n",
      "Success: 125 images for Colum Eastwood in 0m 10.4s\n",
      "Attempt 1/3: Fetching Ecosia results for 'Jim Allister'\n",
      "Successfully collected 125 images for 'Jim Allister'\n",
      "Success: 125 images for Jim Allister in 0m 10.4s\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(uk_politicians_24):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "            politician_array_ecosia, image_links_ecosia = get_image_links_ecosia(\n",
    "                p, \n",
    "                num_results,\n",
    "                headless=False\n",
    "            )\n",
    "            \n",
    "            elapsed = time.time() - start_time\n",
    "            mins, secs = divmod(elapsed, 60)\n",
    "            \n",
    "            if image_links_ecosia:\n",
    "                print(f\"Success: {len(image_links_ecosia)} images for {p} in {int(minutes)}m {seconds:.1f}s\")\n",
    "                image_link_list_ecosia.extend(image_links_ecosia)\n",
    "                politician_list_ecosia.extend(politician_array_ecosia)\n",
    "            else:\n",
    "                print(f\"Warning: No images found for {p}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Critical error processing {p}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43ce2bd3-2ed1-4f88-b6b2-312bb5f185f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2125 2125\n"
     ]
    }
   ],
   "source": [
    "print(len(image_link_list_ecosia), len(politician_list_ecosia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0e04d97-fa3d-4da5-81a8-d1dc4dcd8f26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2120                                                https://www.irishnews.com/resizer/v2/BI2CBC5MBNA2TC5EZAOSG2NJSU.jpg?smart=true&auth=3e24a792c0a60599ab7b446f2d6674c793f89fe43d385b5075bcd42f70b52ebc&width=1200&height=630\n",
       "2121                                                https://www.irishnews.com/resizer/v2/VYM2AWE3A5IJNBALYLQC63YOGM.jpg?smart=true&auth=7c13aba9e15507b0aee0f7bff3f94cc972dcd03a0d47f6c8b3bdc56a69fa68f0&width=1200&height=630\n",
       "2122    https://media.gettyimages.com/id/832883764/photo/jim-allister-the-democratic-unionist-partys-sole-mep-announces-his-resignation-from-the-dup-at.jpg?s=612x612&w=gi&k=20&c=7NfUiSRRV3G27bFJWW9-b_J3PPxugYb7tc_nFabrlG0=\n",
       "2123    https://media.gettyimages.com/id/832883828/photo/jim-allister-the-democratic-unionist-partys-sole-mep-announces-his-resignation-from-the-dup-at.jpg?s=612x612&w=gi&k=20&c=JTnFgtUsXoGuRohUBrzEZa-Yv8QgCVUx1oafZEicMKE=\n",
       "2124                                                                                                              https://i2-prod.belfastlive.co.uk/incoming/article28547518.ece/ALTERNATES/s615/0_300124JP1Stormont023JPG.jpg\n",
       "Name: img_link, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ecosia = pd.DataFrame({'politician': politician_list_ecosia, 'img_link': image_link_list_ecosia, 'engine': 'ecosia'})\n",
    "df_ecosia['img_link'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb47d729",
   "metadata": {},
   "source": [
    "### Combine DuckDuckGo, Bing and Ecosia dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ef033a7-9420-4c72-afe0-777b0d4df345",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_imgref_df = pd.concat([df_ecosia, df_bing, df_ddg], axis=0, ignore_index=True)\n",
    "uk_imgref_df = uk_imgref_df.sort_values(by=['politician', 'engine'])\n",
    "uk_imgref_df = uk_imgref_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5074ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_imgref_df.to_pickle('datasets/train_test/UK/uk_searchengine_imgref_results.pkl')\n",
    "uk_imgref_df.to_csv('datasets/train_test/UK/uk_searchengine_imgref_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbb47b7",
   "metadata": {},
   "source": [
    "### Collect training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae07db59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wiesruyters/miniconda3/envs/multimodalmedia/lib/python3.12/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:118: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CoreMLExecutionProvider, AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/wiesruyters/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/wiesruyters/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/wiesruyters/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/wiesruyters/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/wiesruyters/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "app = FaceAnalysis(\n",
    "    name='buffalo_l',\n",
    "    providers=['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    ")\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586a957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filename(url, p, face_index):\n",
    "    url_hash = hashlib.md5(url.encode()).hexdigest()[:8]\n",
    "    return f\"{url_hash}_{p}_{face_index}.jpg\"\n",
    "\n",
    "def download_image(url, timeout=15):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, stream=True, timeout=timeout)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Verify that the ref leads to an image\n",
    "        if 'image' not in response.headers.get('Content-Type', ''):\n",
    "            raise ValueError(\"Oops... no image found here!\")\n",
    "            \n",
    "        image = np.asarray(bytearray(response.content), dtype=\"uint8\")\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        if image is None:\n",
    "            raise ValueError(\"Failed to decode image\")\n",
    "            \n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {url[:50]}...: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_images(df, output_base):\n",
    "    pbar = tqdm(df.iterrows(), total=len(df), desc=\"Processing training images\")\n",
    "    \n",
    "    for idx, row in pbar:\n",
    "        politician = row['politician']\n",
    "        img_url = row['img_link']\n",
    "     \n",
    "        politician_safe = \"\".join(c if c.isalnum() else \"_\" for c in politician)\n",
    "        politician_dir = os.path.join(output_base, politician_safe)\n",
    "        os.makedirs(politician_dir, exist_ok=True)\n",
    "        \n",
    "        # Save image with retry\n",
    "        img = None\n",
    "        for attempt in range(3): # Attempts\n",
    "            img = download_image(img_url)\n",
    "            if img is not None:\n",
    "                break\n",
    "            time.sleep(1)\n",
    "        \n",
    "        if img is None:\n",
    "            continue\n",
    "        \n",
    "        # Detect faces using the Insightface app (confidence threshold)\n",
    "        faces = app.get(img)\n",
    "        \n",
    "        # Filter\n",
    "        faces = [face for face in faces if face.det_score > 0.6]\n",
    "        \n",
    "        if not faces:\n",
    "            continue\n",
    "        \n",
    "        # Process faces\n",
    "        for i, face in enumerate(faces):\n",
    "            # Bounding box\n",
    "            bbox = face.bbox.astype(int)\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            \n",
    "            # Dynamic padding based on face size\n",
    "            padding_factor = min(0.3, 100/max(x2-x1, y2-y1))  # Slightly larger pad for small faces\n",
    "            h, w = y2 - y1, x2 - x1\n",
    "            x1 = max(0, x1 - int(padding_factor * w))\n",
    "            y1 = max(0, y1 - int(padding_factor * h))\n",
    "            x2 = min(img.shape[1], x2 + int(padding_factor * w))\n",
    "            y2 = min(img.shape[0], y2 + int(padding_factor * h))\n",
    "            \n",
    "            # Crop \n",
    "            face_crop = img[y1:y2, x1:x2]\n",
    "            if face_crop.size == 0:\n",
    "                continue\n",
    "                \n",
    "            # Generate filename and save\n",
    "            face_filename = generate_filename(img_url, politician, i)\n",
    "            save_path = os.path.join(politician_dir, face_filename)\n",
    "            \n",
    "            try:\n",
    "                # Save\n",
    "                cv2.imwrite(save_path, face_crop, [int(cv2.IMWRITE_JPEG_QUALITY), 90])\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving {save_path}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2123d800",
   "metadata": {},
   "source": [
    "NOTE: this function is run only once. After it ran, and the facial images are collected, a manual correction is applied. With drag-and-drop, the image samples are put in the folders that contain the right label (here: politician name). <br>\n",
    "DO NOT RUN THIS FUNCTION; the faces are already collected and corrected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "becfadc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process_images(, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabb7a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95af11b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embedding_on_the_wall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
